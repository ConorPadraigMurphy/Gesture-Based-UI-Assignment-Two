{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Gesture Based UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN From Scratch - Default Image Colour\n",
    "Image size = 128 x 128<br/>\n",
    "Image colour = RGB<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_SIZE = (128, 128) #Image size of 128 x 128\n",
    "BATCH_SIZE = 32\n",
    "DATASET_PATH = \"hagridset\"\n",
    "SEED = 399177 #G00399177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125912 files belonging to 18 classes.\n",
      "Using 88139 files for training.\n",
      "Found 125912 files belonging to 18 classes.\n",
      "Using 37773 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# This code sets up two TensorFlow Keras image datasets for training and validation/testing. The `train_dataset` is created from the \n",
    "# `DATASET_PATH` directory, with a 70/30 split for training and validation data. The `validation_and_test_dataset` is also created from\n",
    "# the `DATASET_PATH` directory, with the same 70/30 split. The `test_dataset` is then created by taking the last 2/3 of the `validation_and_test_dataset`,\n",
    "# and the `validation_dataset` is created by skipping the last 2/3 of the `validation_and_test_dataset`.\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(DATASET_PATH,\n",
    "                                                            shuffle=True,\n",
    "                                                            image_size=IMAGE_SIZE, validation_split=0.3\n",
    "                                                           , subset='training', label_mode='categorical', \n",
    "                                                           seed=SEED, batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_and_test_dataset = tf.keras.utils.image_dataset_from_directory(DATASET_PATH,\n",
    "                                                            shuffle=True,\n",
    "                                                            image_size=IMAGE_SIZE, validation_split=0.3\n",
    "                                                           , subset='validation',label_mode='categorical',\n",
    "                                                           seed=SEED, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_batches = tf.data.experimental.cardinality(validation_and_test_dataset)\n",
    "\n",
    "test_dataset_grayscale = validation_and_test_dataset.take((2*val_batches) // 3)\n",
    "validation_dataset_grayscale = validation_and_test_dataset.skip((2*val_batches) // 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  18\n"
     ]
    }
   ],
   "source": [
    "# Get the number of classes from the data generator\n",
    "NUM_CLASSES = len(train_dataset.class_names)\n",
    "print(\"Classes: \",NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The data augmentation layers is used to artificially expand the training dataset by\n",
    "#applying random transformations to the input images, such as horizontal flipping and\n",
    "#rotation. This can help the model generalize better and improve its performance on\n",
    "#unseen data.\n",
    "\n",
    "data_augmentation_layers = tf.keras.Sequential([\n",
    "    # layers.RandomFlip(\"horizontal\"),\n",
    "    # layers.RandomRotation(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model from scratch\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1],3)))\n",
    "model.add(data_augmentation_layers)\n",
    "model.add(layers.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_8 (Sequential)   multiple                  0         \n",
      "                                                                 \n",
      " tf.math.truediv_1 (TFOpLamb  (None, 128, 128, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_1 (TFOpLam  (None, 128, 128, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 18)                9234      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,723,922\n",
      "Trainable params: 9,234\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configures an EarlyStopping callback for a Keras model.\n",
    "\n",
    "# This callback monitors the validation loss during training and stops the training\n",
    "# if the validation loss does not improve for 5 epochs. It also restores the\n",
    "# weights of the model to the best performing weights during training.\n",
    "\n",
    "# Args:\n",
    "#     monitor (str): The metric to monitor for early stopping. In this case, it is\n",
    "#         set to 'val_loss', which means the validation loss.\n",
    "#     patience (int): The number of epochs to wait before stopping the training if\n",
    "#         the monitored metric does not improve.\n",
    "#     restore_best_weights (bool): If True, the model will be restored to the\n",
    "#         weights that had the best value of the monitored metric.\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2755/2755 [==============================] - 30s 11ms/step - loss: 2.1926 - accuracy: 0.2948 - val_loss: 1.7166 - val_accuracy: 0.4520\n",
      "Epoch 2/10\n",
      "2755/2755 [==============================] - 30s 11ms/step - loss: 1.4155 - accuracy: 0.5427 - val_loss: 1.3115 - val_accuracy: 0.5742\n",
      "Epoch 3/10\n",
      "2755/2755 [==============================] - 30s 11ms/step - loss: 1.0683 - accuracy: 0.6535 - val_loss: 1.2029 - val_accuracy: 0.6264\n",
      "Epoch 4/10\n",
      "2755/2755 [==============================] - 30s 11ms/step - loss: 0.8418 - accuracy: 0.7270 - val_loss: 1.2123 - val_accuracy: 0.6366\n",
      "Epoch 5/10\n",
      "2755/2755 [==============================] - 30s 11ms/step - loss: 0.6682 - accuracy: 0.7811 - val_loss: 1.3201 - val_accuracy: 0.6431\n",
      "Epoch 6/10\n",
      "2755/2755 [==============================] - 30s 11ms/step - loss: 0.5225 - accuracy: 0.8285 - val_loss: 1.5034 - val_accuracy: 0.6386\n",
      "Epoch 7/10\n",
      "2755/2755 [==============================] - 29s 11ms/step - loss: 0.4169 - accuracy: 0.8616 - val_loss: 1.7840 - val_accuracy: 0.6330\n",
      "Epoch 8/10\n",
      "2755/2755 [==============================] - 30s 11ms/step - loss: 0.3304 - accuracy: 0.8902 - val_loss: 1.9482 - val_accuracy: 0.6361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2867162a710>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trains the model on the provided training dataset and evaluates it on the validation dataset. The training runs for 10 epochs and uses the provided callback function to monitor and control the training process.\n",
    "\n",
    "# Parameters:\n",
    "# - train_dataset (tf.data.Dataset): The training dataset.\n",
    "# - validation_dataset (tf.data.Dataset): The validation dataset.\n",
    "# - epochs (int): The number of training epochs.\n",
    "# - callbacks (list): A list of callback functions to use during training.\n",
    "model.fit(train_dataset,  validation_data=(validation_dataset_grayscale), epochs=10, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64x64: With the contrast at 0.5 epoch tens accuracy was 0.5199 </br>\n",
    "64x64: with just flipping and rotation it had an accuracy of 0.5697</br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787/787 [==============================] - 5s 6ms/step - loss: 1.1936 - accuracy: 0.6260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.1936277151107788, 'accuracy': 0.625952959060669}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates the model on the test dataset and returns a dictionary of evaluation metrics.\n",
    "\n",
    "# Arguments:\n",
    "# - test_dataset: The dataset to evaluate the model on.\n",
    "# - return_dict: If True, the method returns a dictionary of evaluation metrics. If False, it returns a list of evaluation metrics.\n",
    "model.evaluate(test_dataset_grayscale, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    stop_inverted\n",
       "dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_image = np.array(Image.open(\"MyHandStop.jpg\").resize((IMAGE_SIZE[0],IMAGE_SIZE[1])))\n",
    "my_image = my_image.reshape(1,IMAGE_SIZE[0],IMAGE_SIZE[1],3)\n",
    "\n",
    "prediction_of_my_image = model.predict(my_image)\n",
    "pd.DataFrame(prediction_of_my_image, columns=class_names).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN from Scatch - Grayscale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_SIZE = (128, 128) #Image size of 128 x 128\n",
    "BATCH_SIZE = 32\n",
    "DATASET_PATH = \"hagridset\"\n",
    "SEED = 399177 #G00399177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess images by converting them to grayscale\n",
    "def preprocess_image(image, label):\n",
    "    # Convert image to grayscale\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    # Normalize the pixel values to the range [0,1]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125912 files belonging to 18 classes.\n",
      "Using 88139 files for training.\n",
      "Found 125912 files belonging to 18 classes.\n",
      "Using 37773 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# This code sets up two TensorFlow Keras image datasets for training and validation/testing. The `train_dataset` is created from the \n",
    "# `DATASET_PATH` directory, with a 70/30 split for training and validation data. The `validation_and_test_dataset` is also created from\n",
    "# the `DATASET_PATH` directory, with the same 70/30 split. The `test_dataset` is then created by taking the last 2/3 of the `validation_and_test_dataset`,\n",
    "# and the `validation_dataset` is created by skipping the last 2/3 of the `validation_and_test_dataset`.\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(DATASET_PATH,\n",
    "                                                            shuffle=True,\n",
    "                                                            image_size=IMAGE_SIZE, validation_split=0.3\n",
    "                                                           , subset='training', label_mode='categorical', \n",
    "                                                           seed=SEED, batch_size=BATCH_SIZE)\n",
    "NUM_CLASSES = len(train_dataset.class_names)\n",
    "CLASS_NAMES = train_dataset.class_names\n",
    "# Apply preprocessing to train_dataset\n",
    "train_dataset_grayscale = train_dataset.map(preprocess_image)\n",
    "\n",
    "validation_and_test_dataset = tf.keras.utils.image_dataset_from_directory(DATASET_PATH,\n",
    "                                                            shuffle=True,\n",
    "                                                            image_size=IMAGE_SIZE, validation_split=0.3\n",
    "                                                           , subset='validation',label_mode='categorical',\n",
    "                                                           seed=SEED, batch_size=BATCH_SIZE)\n",
    "# Apply preprocessing to validation_and_test_dataset\n",
    "validation_and_test_dataset_grayscale = validation_and_test_dataset.map(preprocess_image)\n",
    "\n",
    "val_batches = tf.data.experimental.cardinality(validation_and_test_dataset)\n",
    "\n",
    "test_dataset_grayscale = validation_and_test_dataset.take((2*val_batches) // 3)\n",
    "validation_dataset_grayscale = validation_and_test_dataset.skip((2*val_batches) // 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model from scratch\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1],1)))\n",
    "model.add(data_augmentation_layers)\n",
    "model.add(layers.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2755/2755 [==============================] - 21s 8ms/step - loss: 2.8904 - accuracy: 0.0583 - val_loss: 2.8905 - val_accuracy: 0.0549\n",
      "Epoch 2/10\n",
      "2755/2755 [==============================] - 21s 8ms/step - loss: 2.8904 - accuracy: 0.0585 - val_loss: 2.8906 - val_accuracy: 0.0550\n",
      "Epoch 3/10\n",
      "2755/2755 [==============================] - 21s 8ms/step - loss: 2.8904 - accuracy: 0.0582 - val_loss: 2.8906 - val_accuracy: 0.0550\n",
      "Epoch 4/10\n",
      "2755/2755 [==============================] - 21s 8ms/step - loss: 2.8904 - accuracy: 0.0582 - val_loss: 2.8906 - val_accuracy: 0.0548\n",
      "Epoch 5/10\n",
      "2755/2755 [==============================] - 21s 8ms/step - loss: 2.8904 - accuracy: 0.0583 - val_loss: 2.8906 - val_accuracy: 0.0548\n",
      "Epoch 6/10\n",
      "2755/2755 [==============================] - 21s 8ms/step - loss: 2.8904 - accuracy: 0.0584 - val_loss: 2.8906 - val_accuracy: 0.0548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2867165fd30>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset_grayscale,  validation_data=(validation_dataset_grayscale), epochs=10, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787/787 [==============================] - 4s 4ms/step - loss: 2.8904 - accuracy: 0.0581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 2.8904130458831787, 'accuracy': 0.05805273354053497}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset_grayscale, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicted class: stop_inverted\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image\n",
    "my_image = Image.open(\"MyHandStop.jpg\").resize((IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
    "\n",
    "# Convert the image to grayscale if necessary\n",
    "my_image = my_image.convert(\"L\")\n",
    "\n",
    "# Convert the image to numpy array\n",
    "my_image_array = np.array(my_image)\n",
    "\n",
    "# Expand dimensions to match the model's input shape\n",
    "my_image_array = np.expand_dims(my_image_array, axis=0)\n",
    "my_image_array = np.expand_dims(my_image_array, axis=-1)\n",
    "\n",
    "# Predict the class probabilities\n",
    "prediction_of_my_image = model.predict(my_image_array)\n",
    "\n",
    "# Get the index of the predicted class (the class with the highest probability)\n",
    "predicted_class_index = np.argmax(prediction_of_my_image)\n",
    "\n",
    "# Map the predicted class index to the corresponding class name\n",
    "predicted_class_name = CLASS_NAMES[predicted_class_index]\n",
    "\n",
    "print(\"Predicted class:\", predicted_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1],3),\n",
    "    include_top=False)\n",
    "base_model.trainable = False\n",
    "x = data_augmentation_layers(inputs)\n",
    "x = tf.keras.applications.xception.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES)(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\"), but it was called on an input with incompatible shape (None, 128, 128, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\"), but it was called on an input with incompatible shape (None, 128, 128, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"vgg16\" \"                 f\"(type Functional).\n    \n    Input 0 of layer \"block1_conv1\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 128, 128, 1)\n    \n    Call arguments received by layer \"vgg16\" \"                 f\"(type Functional):\n      • inputs=tf.Tensor(shape=(None, 128, 128, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_xo26bfr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Conor\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"vgg16\" \"                 f\"(type Functional).\n    \n    Input 0 of layer \"block1_conv1\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 128, 128, 1)\n    \n    Call arguments received by layer \"vgg16\" \"                 f\"(type Functional):\n      • inputs=tf.Tensor(shape=(None, 128, 128, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,  validation_data=(validation_dataset_grayscale), epochs=10, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset_grayscale, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch ten transfer learning: val_accuracy: 0.3462"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
